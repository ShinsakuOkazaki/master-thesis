\chapter{Related Work}
\label{chapter:relatedwork}
\thispagestyle{myheadings}

\graphicspath{{2_RelatedWork/Figures/}}

\section{Memory Management in Rust}
\label{sec:history}
\input{2_RelatedWork/model/rust_memory_management}


\section{State of the Art}
\label{sec:history}
\input{2_RelatedWork/model/spark}


\section{Memory Management Problems of Java}
\label{sec:history}
\input{2_RelatedWork/model/manual_memory_management}

\section{Serialization}
\label{sec:history}
\input{2_RelatedWork/model/serialization}


\section{Experiment of Memory Allocation}
\label{sec:history}
This experiment is to test how static and dynamic memory allocation of Java and Rust behave. For the assessment, Element addition to ArrayList in the case of Java and Vector in the case of Rust 
is emploied here. These data stractures are resizable and we have control to set initial size. There are two parameters; initial size of ArrayList or Vector and thier final size after additions of elements. 
We are interested in the impact to memory allocation by initial allocation and expantion to runtime.

First, an ArrayList and an Vector are created with specified initial size. Then, in a loop, a element is added for each iteration until the size of the ArrayList or Vector get the specified final size. 
Each data structure has a different resizing strategy. When an ArrayList hits current limit of its size and expands the limit, it doubles the current size.  
While Vector does not have specific strategy for its resizing, the expantions of size of both ArrayList and Vector might affect the digradation of runtime performance.

To perform benchmarks, we use Java Microbenchamrk Hardness (JMH) for Java and Criterion for Rust. The benchmark time is calculated mean from several iterarions. 
We warm up before the execution. The parameters are set in combination of initial size, 10, 100, 1000, and 10000 and final size, 9, 99, 999, 9999. 
The results are shown in Figure 2-4 and 2-5. 

Discussions here are separated to two cases: when initial size is set bigger than final size and when final size is set bigger than initial size. 
For ArrayList in Java, it shows performance significant degradation when the initial size is bigger than final size. When we create ArrayList with intial size of 1000 and add 99 elements 
to the ArrayList, the the average execution time is 1125 ns. However, the average excution time when we create ArrayList with intial size of 100 and add 99 elements is 623 ns. 
This degration is caused by the cost of initializing the large array. On the other hand, Rust Vector does not have significant cost for the initialization of size compared to the cost of addition of elements. 
In the case of Vector with initial size of 1000 and add 99 elements to the Vector, the average excution is 320 ns. In the case of the initial size of 100 and 99 elements additions, 
the average excution is 279 ns. This is such small degradation compared to element addition in Vector. 

In ArrayList when the initial size is smaller than the final size, there can be degradation in performance. When its initial size and final size are set 100 and 999 respectively, 
the average execution time is 10884 ns. However when its initial size and final size are set 1000 and 999 respectively, the average execution time is 4250 ns. 
This result shows the degradation of in performance caused by the copy of existing elements into newly allocated array whose size is double of the last array.

This characteristic can be seen in the case of Vector in Rust. Vector with initial size 100 and final size 999 performs the average excution time 3514 ns, 
but one with initial size 1000 and final size 999 performs 2723 ns. When the Vector reachs its capacity, it allocates a larger buffer and copies the present elements to it.
This cost results in the degradation of the average excution time.

\begin{figure}[htb]
    \includegraphics[width=15cm]{java_arraylist.eps}
    \caption{Memory allocation of ArrayList in Java}
    \label{fig:Sampling}
\end{figure}

\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_vector.eps}
    \caption{Memory allocation of Vector in Rust}
    \label{fig:Sampling}
\end{figure}



\section{Experiment of Memory Allocation for Different Element Type.}
\label{sec:history}
This experiment is to test how static and dynamic memory allocation of Java and Rust behave. For the assessment, Element addition to ArrayList in the case of Java and Vector in the case of Rust 
is emploied here. These data stractures are resizable and we have control to set initial size. There are two parameters; initial size of ArrayList or Vector and thier final size after additions of elements. 
We are interested in the impact to runtime performance by initializing memory allocation and dynamicaly allocating memory space.

First, an ArrayList and an Vector are created with specified initial size. Then, in a loop, a element is added for each iteration until the size of the ArrayList or Vector get the specified final size. 
Each data structure has a different resizing strategy. When an ArrayList hits current limit of its size and expands the limit, it doubles the current size.  
While Vector does not have specific strategy for its resizing, the expantions of size of both ArrayList and Vector might affect the digradation of runtime performance.

Second, four types of element are used for elements addition to each data structure: integer, array of charactors, string, and Customer object. 
Assamption is that there would be different behavior between element additions of dynamically resizable and static size objects. 
Customer object has three fields. These fields are total order, weight of order, and zip code whose types are integer (i32 in rust), double (f32 in rust), and string respectively.
Figure 2-6 and 2-7 are representations of customer objects in Java and Rust.

Figure 2-10, 2-11, 2-12, and 2-13 represent the result of the experiments. For both data structures, integer elements addition shows the fastest runtime among all object types. 
This is because the compilers know each integer need 4 bytes to be stored in memory so that the space for memory that should be allocated is easily inspected. 
For the same reason, the initialization of data structures whose elements are integers alaways improves runtim performance.

The elements addition of strings and array of character behave similally among each languages. These two types of elements addition perform the similar speed and significantly slower than integer addition. 
Customer object addition is the slowest in Java. However, in Rust the addition of Customer object is the second fastest among all element typs.
The impacts of initialization of Java ArrayList vary among elemet types. On the other hand, the initailization Rust Vector always improves runtime performance for any of 4 types of elements addition.


\begin{figure}[htb]
    \begin{lstlisting}
        class Customer {
            int totalOrder;
            double weightOrder;
            String zipCode;
        }
    \end{lstlisting}
    \caption{Representation of Customer object in Java.}
    \label{fig:Sampling}    
\end{figure}

\begin{figure}[htb]
    \begin{lstlisting}
        struct Customer {
            total_order: i32,
            weight_order: f32,
            zip_code: String,
        }
    \end{lstlisting}
    \caption{Representation of Customer object in Rust.}
    \label{fig:Sampling}
\end{figure}

\begin{figure}[htb]
    \includegraphics[width=15cm]{java_arraylist_log.eps}
    \caption{Memory allocation of Java ArrayList}
    \label{fig:Sampling}
\end{figure}

\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_vector_log.eps}
    \caption{Memory allocation of Rust Vector}
    \label{fig:Sampling}
\end{figure}


\begin{figure}[htb]
    \includegraphics[width=15cm]{java_arraylist_difference.eps}
    \caption{Difference of Memory allocation of Java ArrayList between Non-initialization and Initialization}
    \label{fig:Sampling}
\end{figure}

\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_arraylist_difference.eps}
    \caption{Difference of Memory allocation of Rust Vector between Non-initialization and Initialization}
    \label{fig:Sampling}
\end{figure}


\section{Elements Copy and Insertion into Size-initialized Vector in Rust.}
\label{sec:history}
In this experiment, four methods are used to insert elements into vector in Rust. One is clone method which performs bitwise deep copy. 
Another is clone\_from which also performs bitwise deep copy, but copies elements of the vector to distination vector rather than 
creating new one. We initialize the distination vector with the same size to the number of elements we insert into it. 
Another is copy\_nonoverlapping function which copies values from source to distination memory region. 
The other is pushing elements of source to distination vector one by one. Insertions of elements with 4 size are conducted 1000000, 1500000, 10000000, 15000000, and, 
their runtimes for each elements type, integer and String are measured. 


The figure shows the result of the experiment. Among the runtime performances of integer insertion for every methods, 
clone, clone\_from, and copy\_nonoverlapping method shows the similar performance. However, the pushing the copy of elements one by one has much slower runtime performance 
compared to the rest. This is because integer elements are allocated contiguously in the memory, so that accessing address of memory by pointer reads some next address. 
This boosts the copy and insertion of elements. 

On the other hand, all of methods show the similar runtime performance in experiment for String object insertion. 
This is because String object is not stored in contiguous memory region. The vector stores pointer to the object and 
process need to access around different memory region again and again to deeply copy the object.

\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_various_insertion.eps}
    \caption{Runtime of elements copy from one vector and insertion to the other vector.}
    \label{fig:Sampling}
\end{figure}



\section{Access time to elements in vector}
\label{sec:history}
In this experiment, whether mutability has impacts to operation on the object in terms of runtime performance. 
According to the experiment, there is no difference on accessing to elements of mutable and immutable vector.

\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_various_access.eps}
    \caption{Runtime of elements copy from one vector and insertion to the other vector.}
    \label{fig:Sampling}
\end{figure}

\section{Access time to onwned, borrowed, and sliced field of object}
\label{sec:history}
In this experiment, differences of access time to among owned, borrowed, and sliced are observed. 
Each variable has slightly different use of memomry. 


\begin{figure}[htb]
    \begin{lstlisting}
        struct CustomerOwned {
            key: i32,
            age: i32,
            num_purchase: i32,
            total_purchase: f64,
            duration_spent: f64, 
            duration_since: f64,
            zip_code: String,
            address: String,
            country: String,
            state: String,
            first_name: String,
            last_name: String,
            province: String,
            comment: String, 
            order: OrderOwned
        }

        struct CustomerBorrowed<'a> {
            key: &'a i32,
            age: &'a i32,
            num_purchase: &'a i32,
            total_purchase: &'a f64,
            duration_spent: &'a f64, 
            duration_since: &'a f64,
            zip_code: &'a String,
            address: &'a String,
            country: &'a String,
            state: &'a String,
            first_name: &'a String,
            last_name: &'a String,
            province: &'a String,
            comment: &'a String, 
            order: &'a OrderBorrowed<'a>
        }

        struct CustomerSlice<'a> {
            key: &'a i32,
            age: &'a i32,
            num_purchase: &'a i32,
            total_purchase: &'a f64,
            duration_spent: &'a f64, 
            duration_since: &'a f64,
            zip_code: &'a str,
            address: &'a str,
            country: &'a str, 
            state: &'a str,
            first_name: &'a str,
            last_name: &'a str,
            province: &'a str,
            comment: &'a str,
            order: &'a OrderSlice<'a>
        }

        struct CustomerRc {
            key: Rc<i32>,
            age: Rc<i32>,
            num_purchase: Rc<i32>,
            total_purchase: Rc<f64>,
            duration_spent: Rc<f64>, 
            duration_since: Rc<f64>,
            zip_code: Rc<String>,
            address: Rc<String>,
            country: Rc<String>,
            state: Rc<String>,
            first_name: Rc<String>,
            last_name: Rc<String>,
            province: Rc<String>,
            comment: Rc<String>, 
            order: Rc<OrderRc>
        }
    \end{lstlisting}
    \caption{Representation of Customer object in Rust.}
    \label{fig:Sampling}
\end{figure}


\section{Accessment of different reference methods in Rust}
\label{sec:history}
The goal of this experiment is to assess efficiency of different reference strategies in Rust, borrowing and reference counting. 

By levaraging reference counting, a value can be shared like what borrowing plays the role in Rust programming. 
The difference is that reference counting checks number of reference pointing to the actual data and makes sure the data is not deleted 
until all the references are dereferenced. Using reference counting is sometimes preferable approach for developers, 
we do not have care about lifetime which is usually troublesome when we use borrowing approach many times in our code. 
However, the possible problem regarding to reference counting is the cost for tracking the number of references. 
Having this assumption, this experiment will show difference of behavior among reference countinig and borrowing.

In this experiment, CustomerBorrowed and CustomerRc in figure are used to see difference of dropping time among borrowing and reference counting. 
In the CustomerRc and OrderRc struct, all fields take reference counting (Rc$<$T$>$). Similaly to the experiment in the last section, 
vectors of CustomerRc and CustomerBorrowed are created and droped the elements one by one. 

The result shows significant difference of dropping time among the two objects; deletion of CustomerRc is much slower than CustomerBorrowed. 
This is because reference counters which are feilds of CustomerRc have to check the number of reference pointing to the actual content and decide 
deallocate the memory or not. However, memory management and lifetime strategy of borrowing is already determined at compile time.

\section{Time to Drop Reference vs Reference Counting}
\label{sec:history}
In this experiment, an assessment is conducted to valify whether there is difference between behavior of borrowing and reference counting. 
These two methods can be used in similar situation. Especially, when we want reference to an original variable and keep the original variable until all of references are dereferenced, 
we can have reference with both storategies, borrowing and reference counting. One advantage of using reference counting is that we do not have to pay attention to lifetime.
However, the assumption here is that use of reference counting might be computationally expenesive than borrowing, because reference counting has to track the number of reference pointing to the value. 
Considered this assumption, we assess difference of time for dropping reference using borrowing and reference counting strategies. 

Similally to the last section, we implement struct whose fields are borrowing reference and reference counting and measure the time to drop the struct. 

The result shows the time to drop borrowing reference is significatly faster than reference counting. This says that we should use borrwoing storategies whenever high performance computation is critical.


\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_droptime_borring_rc.eps}
    \caption{Runtime for Droping to fields of Customer Object}
    \label{fig:Sampling}
\end{figure}

\section{Possible Graph Structure in Rust}
\label{sec:history}
In Rust, there are two essential problems to construct graph structure, lifetime and mutability. 

The first problem is about what kind of pointer to use to point to other nodes. 
Since graph can be cyclic, so the ownership consept in Rust is violated if we use Box$<$Node$>$.

All of graph structure are immutable at least at creation time. Because graph may have cyclic, 
we can not create graph at one statement. Although edge of graph has to be mutable to create entire graph structure, 
we might need multiple references to edges, which violates basic rule of Rust programming.

One solution is to use raw pointers. This is the most flexible approach, but also the most dangerous. 
By taking this way, we are ignoring all the benefits of Rust.

\section{Experiment for Multithread}
\label{sec:history}
Experiment for multithreading in Rust is interesting, because there are many memory allocation and deallocation in each threads.
This is because each thread offten need to form independent memory state to each other to perform computation concurrently safely.
In addition, the multithreading strategy can be planned in different ways in Rust using different concurrent computation tools, 
Mutex, Arc, spawn, channel, scope, and so on.

Currently available plan
\begin{itemize}
    \item spawn, channel and sending data (currently deviding data, but we probably do not need to).
    \item spawn, forkjoin and shared data.(shared data among child and parent).
    \item scope, forkjoin and slice shared data.
    \item Use linkedList instead of Vector (Each node can be sharable data structure). When we have complex object of elements in vector, we want to copy the pointer to the object.
    \item Compare performace on LinkedList which is not contiguous allocation, but do not need additional memory allocation and Vec.
\end{itemize}



\section{Note for next}
\label{sec:history}
Complex object of elements copy and insertion among vector is worth to experiment. This can be compared with Java,
because memory layouts of struct in Rust and class in Java are different. Rust stores fieds in the contiguous memory region. 
However, Java stores field elements to different region.

Complex object whose fields has reference elemenets insertion to vector can be evaluated. Operation to the fields can be little 
more expensive because the pointer to the value of the field is not stored in contiguous memory region.

Generic type and static type function can be compared. 

To optimise access to String elements of vector, smallstring can be improve the runtime performance. 
This is because the smallstring optimization enables short length of string on stack as byte array. 
This string type sets condition where it makes decition where the string is stored on heap or stack as array at certain length.

Comparing operation on reference and owned variable is also interested to examine.

Comparing operation on various smart pointer type. 
Rc$<$T$>$ enables value to have multiple owners, but the value should be immutable. Rc$<$T$>$ is used in case of single thread. 
When the situation is multi-thread, Arc$<$T$>$ is used. Arc$<$T$>$ performs atomic operation, so it is more expensive than Rc$<$T$>$. 
When we need to mutate value of Rc$<$T$>$, RefCell$<$T$>$ can be useful. RefCell$<$T$>$ allow us to have mutiple mutable reference and immutable
of reference mutable or immutable variable at the same time. When the mutability consistency is voilented, it terminates program during runtime. 
That is why RefCell$<$T$>$ is expensive so that the state of mutable consistency should tracked. 
As Cell$<$T$>$, the value is copied in and out of the Cell$<$T$>$ instead of getting refrence to it. 
In addition, Mutex$<$T$>$ provides intetior mutability across multi-thread.

Comparison between mutable and immutable tree or graph structure can be checked. 
This is because tree structure requires Rc$<$T$>$ or Week$<$T$>$ and in addition RefCell$<$T$>$ to make it mutable.

Design experiment for Trait object and Generic function. 
We can have Trait object which is pointer to object which imprements its Trait and use the method of Trait object.
This object has additional information other than just reference to tye original object. 
This is because Rust needs the type information to dynamically calll the right method of Trait object depending on the type of 
original object.
On the other hand, we can have Generic function whose parameter types are Generic types corresponding to Trait. 
When Rust compiles the code, it emits independent function corresponding to every types that implements the Trains specified in parameter.

Vector of Trait object (need to put element into Box) vs Vector of concrete type.


If we keep first created owner until the last phase, we can use borrowing to operate.
If we delete first created owner during the operation, we should use Rc$<$T$>$.
The question would be, we can use Rc$<$T$>$ every where?

Multithread in Rust vs Java

Smart pointer
\begin{itemize}
    \item Box$<$T$>$: Box pointer lets value allocated on heap rather than on the stack.
    \item Rc$<$T$>$: Reference counted pointer lets variable take multiple immutable ownership.
\end{itemize}

Interier mutability
\begin{itemize}
    \item Cell$<$T$>$: For only Copy type, it allows us to mutate variable, even if it is immutable. Howeever, it does not support sharing the variable so that it returns always copy of the value.
    \item RefCell$<$T$>$: This support sharing and interier immutability for all types. This is done by allowing to get mutable reference from immutable variable and push the error detacting time from compile time to runtime.
\end{itemize}    

\section{LLVM}
\label{sec:history}
LLVM (Low Level Virtual Machine) is an umbrella project which contains components of compilation of programming language.
Exsiting compilers have tightly coupled functionalities so that it is not possible to embed them into other applications.
However, the abstract framework of LLVM decouples the functionalities into peaces and the peaces of functionalities can be reused.

In structure of a compiler, there are three main components; flontend, optimizer, and backend. 
In flontend, a develper designs the interface of source programming language in way where it can be optimized by optimizer. 
Then, backend takes optimized code and produce the native machine code. LLVM has a component called LLVM Intermediate Representation (IR), 
which places itself across frontend to optimizer. IR is designed to host mid-level analyses and transformations that you find in optimizer section of a compiler.
High-level language has many common structures and functionalities, so most of all high-level program languages can be represented with IR. 
Once source code is represented with IR, optimizer can easily find pattern and optimize it in faster time. 
IR is useful in terms of flontend. This is because developer of language flontend need to know only how the IR works and use the framework to develop a language.

\section{The existing Big Data tools}
\label{sec:history}
The existing Big Data tools are JVM based. JVM abstract hardware so that JVM can rarely achieve near-native speed. A garbage collector is a

\section{Experiment: Tree aggregate}
\label{sec:history}
Three aggregate can be more memory de/allocation intensive experiment, when we load data from disk line by line to aggregate.
This is because, we will allocate many small objects and deallocate them many times.
We can imitate ShuffledRDDs by writing result to disk and reading it to other thread.  
We can compare to Java implementation for ration of runtime increase.





\section{Todos}
\label{sec:history}
\begin{itemize}
    \item 
    \item Redo the experiment with appropriate size
    \item Document for Memory Management of Java with Garbage Collection and the impact for Big Data tools
    \item The safety of Region Based Memory Management and advantage of using Rust.
    \item Serialize problem 
    \item Document for reference counting(measure dropt time using criterion)
    \item Design experiment for Graph
    \item Design experiment for Multithread
    \item Study about LLVM
\end{itemize}

\section{Done}
\label{sec:history}
\begin{itemize}
    \item Study about OS memory management
\end{itemize}


\section{Time Line}
\label{sec:history}
\begin{itemize}
    \item End Feb: Finish Experiment for Multithread and Graph
    \item Mid May: ML experiment
    \item End May: Redo experiment with bench mark dataset.
    \item Start April: Finish Writing for first revise.
\end{itemize}


\begin{figure}[htb]
    \includegraphics[width=15cm]{rust_merge_sort.eps}
    \caption{mergesort}
    \label{fig:Sampling}
\end{figure}