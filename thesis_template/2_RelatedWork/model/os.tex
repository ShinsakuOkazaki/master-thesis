\subsection{Memory and Process in Operating Systems}
\label{sec:os_mem_process}
A process is a subsection of computation job. A process can work on a CPU core, we can divide process as well.
Basically, each process does not share their memory. However, for multiprocessing, we could avoid this restriction.
Processes can be represented as tree structure, because a process may create other child processes.
Process has 4 states, new, running, waiting, and ready. 
Process is represented in process control block (PCB) with state type, process ID, registers, and so on.
The scheduling for process assigning to CPU core is implemented in queues containing PCB. There are two main queues in this scheduler: 
ready queue and wait queue. The head of process in ready queue is selected for execution and once the process requested I/O request or 
production of child process, the running process will be stored n wait queue. Once the request that the process waiting for end, 
the waiting process will be pushed tail of ready queue. 

Processes executing concurrently in the operating system may be either independent processes or cooperating processes executing in the system.
A process is independent if it does not share data with any other processes. A process cooperating if it can affect or be affected by the 
other processed executing in the system. In cooperating process, there are two kinds, shared memory and message passing. 
In shared memory, it removes restriction of not interfering memory region. Message passing can be useful for distribution systems as well.

For a pair of processes to communicate through message, a socket is needed to be established. 
A socket is identified by an IP address concatenated with a port number. When two process communicate, each process will have socket. 
If another process of the same machine wants to communicate, we need new socket to be established. The protocol used in the socket connection
can be TPC and UDP.

\subsection{Multi-threading and Parallelism}
\label{sec:os_thread}
A thread is a basic unit of CPU utilization, so that a process can have multiple thread. Threads share mainly code and data. 
Multi-threading is increasingly popular as the multicore programming becomes in common, because we can run multiple thread on different core.
Creating thread is much cheaper than creating process and it shares resources so that we do not need additional methods to allow threads to 
communicate each other, such as sharing memory and message passing.

\subsection{Memory management in Operating System}
\label{sec:os_memmanage}
In computer storage hierarchy, the closest storage to CPU is register. It is built into each CPU core and accessible within one cycle of the CPU clock.
However, the same cannot be said of main memory, which is accessed via a transaction on the memory bus. This takes many cycles of the CPU clock.
The remedy is to add fast memory between the CPU and main memory, typically on the CPU chip for faster access. Such a cache plays a role for this.

For the layout of main memory, it must be ensured that each process has a separate memory space, including operation system. 
The base register and limit register, whose roles are lower bound of memory region and specific size of range respectively, can achieve that goal. 

Usually a program resides on a disk as binary executable file. To run, the program must be brought into memory and placed within the context of a process.
The process is bound to corresponding parts of the physical memory. Binding program to memory address is staging process. 
There three stages: compile time, load time execution time. The source program is compiled by compiler producing object file. 
After the compilation, the object file is linked with other object file by linker creating executable file . 
Finally, the executable file will be loaded to run execute. At this run time dynamic library link can be done.

If where the process will reside in memory at compile time, absolute code is generated. If this is unknown at the time, 
the binding will be done at load time. At this time, the compiler must generate relocatable code. Otherwise, the binding will be done at 
execution time.

A process does not interact with addresses of physical memory, instead virtual memory. The memory-management unit (MMU) takes roles to map 
logical address to physical address. OS needs to ensure that any of physical memory spaces of processes do not overlap. 
Since one process can be created and deleted and the corresponding memory space should be de/allocated, 
optimization for use of physical memory space is important; we need to allocate memory contiguously avoiding fragmentation.

There are several approaches to deal with this problems. However, we will focus on paging here, which is the most used method OS use to manage memory.
A frame and page are a unit of Separated physical and virtual memory space in fixed size (4KB or 8KB) respectively.
A process can use as many as pages and corresponding frames obtained by page table matching. This strategy does improve external fragmentation, but not for internal fragmentation.
The smaller size of page has smaller fragmentation, but mapping from page to frame has overhead and also disk I/O is more efficient when the amount of data transfered is larger.



\subsection{Demand Paging}
\label{sec:os_paging}
A process can have multiple pages. However, loading entire executable code from secondary storage to memory is not necessarily needed to 
get jobs done. A strategy used in several operating systems is loading only the portion of programs that are needed, demand page. 

In the storage, some pages currently used are in memory and the others are in secondary storage. 
The page table specifies whether pages are valid or invalid, which means are in memory or not. 
Access to a page marked invalid causes page fault and some steps to resolve the error will be required. 

The first part of process of demand paging would be that we check an internal table to check whether the reference is valid or invalid.
If the reference is valid, the process reads the content from the memory. Otherwise, we terminates the process and find the free frame in 
physical memory. Then, we schedule a secondary storage operation to read the desired page into newly allocated frame. 
When the storage complete reading the page, we modify the internal table to indicate the page is now in memory. 
Finally, we restart the instruction that was interrupted. 

However, there would be a case where the memory does not have any free frame. In this case, a victim frame that will be replaced with new coming frame should be selected. 
To perform this selection efficiently, a modify bit is tracked for each frame or page. The modify bit represents whether the page is modified since it is loaded from secondary storage. 
If the page or frame is modified, when we swap page we need to update the content in the secondary storage. However, it is not modified, we can simply delete the frame and replace with new frame.



% \subsection{Copy on Page}
% \label{sec:os_copypage}
% When a parent process creates child process and if these process shares contents on particular page and modify it, 
% only the page which has the context will be copied.


% \subsection{Threads and Concurrency}
% \label{sec:history}