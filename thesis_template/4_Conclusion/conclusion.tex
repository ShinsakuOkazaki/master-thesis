\chapter{Conclusions}
\label{chapter:Conclusions}
\thispagestyle{myheadings}

% set this to the location of the figures for this chapter. it may
% also want to be ../Figures/3_Body/ or something. make sure that
% it has a trailing directory separator (i.e., '/')!
\graphicspath{{3_Conclusion/Figures/}}

% Quick recap of what we did 
% - The purpose of this research
% - Experiment that we conducted
In this thesis, we have presented a number of experiments to assess better implementation of algorithms 
when one develops Big Data analysis tools with Rust programming. 
Those experiments examine how different variable types, Reference Count (Rc), and different memory management strategies in Rust affect performance of algorithms.

% What we find 
% - The result of our experiments
The results show useful benchmark when one implements Big Data analysis tools.
The different variable types in Rust have similar access time to the memory address of their value. 
Therefore, we do not need to consider such access overheads. 
The drop on Rc or Arc is more expensive than ordinal variables, 
because these shared variables need to check count of reference to its actual value. 
The atomic operation used by Arc may be a cause of overhead in multithread programming in Rust. 

% What is the most significant
% - Use of Reference is depending on Complex object type
% - When we have complex object, we should use Reference count
% - Frequency of memory de/allocation has impact
One of the most notable discussion is selection of whether developers should use sharing (Rc or Arc) or deep-copy. 
In algorithms used to process Big Data, the same elements are used over and over agin. 
In Experiment 4 and 5, we implement the algorithms in different strategies and assess which implementations performs better in runtime.
The result is that the algorithms sharing elements using Arc is more efficient strategy when the shared elements are very complex objects. 
On the other hand, when the elements have light complexity, such as String, the algorithms deep-copying the elements is more faster.
Therefore, the decision of which strategy to use is dependent on how complex element objects are.

% Conclusion acquired from that
% - the design of algorithm is depend on implemetation of complex objects
% - Rust ownership memory management seem to work well
% - We can manually de/allocate memory and compiler can still ensure memory safety.
The other important discussion is how Rust ownership memory management can impact performance of algorithm.
Even though the main concept of ownership is safety of memory, programming patterns using this ownership may determine the frequency and timing of de/allocation. 
Experiment 5 shows the ownership memory management works well; the frequency and timing of de/allocation is fairly reasonable for algorithms to result good runtime performance and memory usage. 
However, when the situation is memory intensive and needs more fast runtime performance, developers need to perform more careful memory managements,such as manually specifying when to deallocate memory.
Rust can check memory-safety of these manual operation at compile time, so such optimizations can be done fairly easy.

% How our conclusion can be applied in real world 
% - Decide data structure implementation that used in Big Data Systems then
% conduct experiment that fits for the best runtime performance.
As we can see in the results of experiment, different memory strategy varies the performance of algorithms in Rust programming.
Which memory management strategy to take depends on what objects to deal with. 
Therefore, development of Big Data analysis tools in Rust programming should be started with objects implementation used in the systems.
Next, one can select suitable memory management strategies. 
Finally, algorithms can be optimized with more dedicated strategies to application setting, such as capacity of memory.